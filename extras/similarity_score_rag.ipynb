{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing similarity search using vector databases, we search for k closest vectors. But how does that work internally?\n",
    "\n",
    "Answer is that each question is converted to a corresponding embedding and then a distance strategy is used to find distance between the vectors. For FAISS, the distance strategy is set to DistanceStrategy.EUCLIDEAN_DISTANCE by default.\n",
    "\n",
    "Now, if we want similarity score to be between -1 to 1, we must use cosine similarity for search similarity score. Here I will demonstrate how to use cosine similarity and compare vectors for their similarity score.\n",
    "\n",
    "Here 1 means vectors are same and -1 means vectors are opposite"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "The above is formula for cosine similarity where `a` and `b` are 2 vectors(embeddings of a string)\n",
    "\n",
    "We will take user query and make vector embeddings as vector `a` and then for all docs in vectorDB, run this formula for vectors of each chunk/document. Then we sort it based on highest similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-community langchain-text-splitters scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk the pdf into chunks and convert them to documents\n",
    "\n",
    "- load the pdf using langchain PyPDFLoader\n",
    "- chunk into sizes of 250 with 20 overlap for context via RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = \"../data/who_stats_2022.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "pdf_pages = loader.load_and_split(text_splitter=text_splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2405"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {'source': '../data/who_stats_2022.pdf', 'page': 8},\n",
       " 'page_content': '33% in 2000. The number of adults aged 30–79 years with raised blood pressure (hypertension) is estimated \\nto have almost doubled to 1.28 billion between 1990 and 2019, mainly due to population growth and ageing.',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(pdf_pages[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want similarity score of chunks with this query\n",
    "\n",
    "For this we have to create embeddings for each page_content as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What was effect of covid 19 in middle east?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_texts = [p.page_content for p in pdf_pages] # get only texts as we focus on similarity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create embeddings using Hugging face functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VS Code\\python\\GenAI-Cookbook\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "# use the open-source embedding function to convert text to embeddings, can choose another function as per leaderboard - https://huggingface.co/spaces/mteb/leaderboard\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = embedding_function.embed_documents(chunk_texts) # gives list of embeddings(which are list of float numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(chunk_embeddings[0])\n",
    "len(chunk_embeddings[0]) # linear vector of length 384 is generated as embedding for 0th chunk text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedding_function.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mquery_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;66;03m# not a numpy array\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "query_embedding.shape # not a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "query_embedding = np.array(query_embedding).reshape(1,-1) # for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = [np.array(ce).reshape(1,-1) for ce in chunk_embeddings] # reshape for cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create cosine similarity and give top 10 similar vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21760679]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(query_embedding, chunk_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is similarity score in range [0,1] for query and chunk embedding based off cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing cosine similarity for all chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = [cosine_similarity(query_embedding, ce) for ce in chunk_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21760679]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2176067916557493"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort based off similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_score_list = [(chunk_texts[i], similarities[i][0][0]) for i in range(len(similarities))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('World \\nHealth \\nStatistics \\n2022\\nMonitoring  \\nhealth for the  \\nSDG s\\nSustainable Development Goals',\n",
       "  0.2176067916557493),\n",
       " ('World \\nHealth \\nStatistics \\n2022\\nMonitoring  \\nhealth for the  \\nSDG s\\nSustainable Development Goals',\n",
       "  0.2176067916557493),\n",
       " ('World health statistics 2022: monitoring health for the SDGs, sustainable development goals\\nISBN 978-92-4-005114-0 (electronic version)\\nISBN 978-92-4-005115-7 (print version)\\n© World Health Organization 2022',\n",
       "  0.23928306724151702)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_score_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_chunk_score_list = sorted(chunk_score_list, key=lambda x: x[1], reverse=True) # sort based on similarity(2nd ele of tuple) in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the top 10 most similar chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('true impact of the COVID-19 pandemic. Iraq and Tunisia also reported \\non monthly total deaths and were able to determine excess deaths \\nin 2020 in comparison to 2019. \\nSeven countries in the Eastern Mediterranean Region have reported',\n",
       "  0.6641347167072867),\n",
       " ('15. Roberton T, Carter ED, Chou VB, Stegmuller AR, Jackson BD, Tam Y, et al. Early estimates of the indirect effects of the COVID-19',\n",
       "  0.6533679664352592),\n",
       " ('• Progression and impact of the COVID-19 pandemic  ..................................................................................................................... 1',\n",
       "  0.6422023115978144),\n",
       " ('Progression \\nand impact of \\nthe COVID-19 \\npandemic01',\n",
       "  0.6185028984897357),\n",
       " ('Classification of Diseases (10th revision) was key to enable countries \\nto identify the impact of COVID-19 to cause deaths within their top \\n10 leading causes of death. Mortality data for Lebanon, Oman, Qatar,',\n",
       "  0.6157655627126775),\n",
       " ('and middle-income countries and compared them with a \\nno-COVID-19 scenario. The pandemic scenarios were: a rapid \\nrecovery in 2021 (“optimistic”); a scenario with a second',\n",
       "  0.6051212821058087),\n",
       " ('36. The impact of COVID-19 on health and care workers: a closer look at deaths. Geneva: World Health Organization; 2021( https:/ /apps.\\nwho.int/iris/handle/10665/345300 , accessed 5 May 2022).',\n",
       "  0.5924630896129958),\n",
       " ('eng.pdf?sequence=1&isAllowed=y , accessed 4 May 2022).\\n4. Osendarp S, Akuoku J, Black R, Headey D, Ruel M, Scott N, et al. The COVID-19 crisis will exacerbate maternal and child',\n",
       "  0.5888074011436205),\n",
       " ('may be higher than currently reported (see below) (8).\\nFig. 1.3.  Cumulative reported COVID-19 deaths, (a) by WHO region and (b) by World Bank income groups, as of 20 April 2022\\nIndia\\nAfrica\\nEuropeAmericas\\nSouth-East AsiaEastern Mediterranean',\n",
       "  0.5849406242588515),\n",
       " ('19. Global excess death associated with COVID-19, January 2020 – December 2021. Geneva: World Health Organization ( https:/ /',\n",
       "  0.5774613632265256)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_chunk_score_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting last 10 least similar chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('against NTDsj \\nData typeComparable estimates Comparable estimatesComparable \\nestimatesPrimary dataComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesPrimary data',\n",
       "  -0.06006841779414178),\n",
       " ('against NTDsj \\nData typeComparable estimates Comparable estimatesComparable \\nestimatesPrimary dataComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesPrimary data',\n",
       "  -0.06006841779414178),\n",
       " ('against NTDsj \\nData typeComparable estimates Comparable estimatesComparable \\nestimatesPrimary dataComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesPrimary data',\n",
       "  -0.06006841779414178),\n",
       " ('against NTDsj \\nData typeComparable estimates Comparable estimatesComparable \\nestimatesPrimary dataComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesPrimary data',\n",
       "  -0.06006841779414178),\n",
       " ('against NTDsj \\nData typeComparable estimates Comparable estimatesComparable \\nestimatesPrimary dataComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesComparable \\nestimatesPrimary data',\n",
       "  -0.06006841779414178),\n",
       " ('or recommended by WHO in preference to others of a similar nature that are not mentioned. Errors and \\nomissions excepted, the names of proprietary products are distinguished by initial capital letters.',\n",
       "  -0.0818026838664241),\n",
       " ('third-party-owned component in the work rests solely with the user.\\nGeneral disclaimers.  The designations employed and the presentation of the material in this publication do not',\n",
       "  -0.08587501525754608),\n",
       " ('requests for commercial use and queries on rights and licensing, see https:/ /www.who.int/copyright. \\nThird-party materials.  If you wish to reuse material from this work that is attributed to a third party, such as',\n",
       "  -0.09934718066236249),\n",
       " ('suggestion that WHO endorses any specific organization, products or services. The use of the WHO logo is \\nnot permitted. If you adapt the work, then you must license your work under the same or equivalent Creative',\n",
       "  -0.10333010245695476),\n",
       " ('Under the terms of this licence, you may copy, redistribute and adapt the work for non-commercial purposes, \\nprovided the work is appropriately cited, as indicated below. In any use of this work, there should be no',\n",
       "  -0.11809664523777069)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_chunk_score_list[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity gives in range [-1,1] where 1 means same and -1 means vector is opposite\n",
    "\n",
    "It seems like the most similar document chunks have data important to answer the query regarding mortality rated in middle east. If we choose the least similar chunks, we will definitely get bad answer.\n",
    "\n",
    "Let's test it with RAG example - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a question answering agent. Based on the context, provide the answer of the following question.\n",
    "Provide concise answer based on the context.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is passed in to format each document retrieved from vector store to get the page content only as context to LLM\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hugging_face_api_key = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\VARUN ARORA\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\" # last result of this\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First RAG chain with most similar docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_context = [item[0] for item in sorted_chunk_score_list[:5]] # extract just the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['true impact of the COVID-19 pandemic. Iraq and Tunisia also reported \\non monthly total deaths and were able to determine excess deaths \\nin 2020 in comparison to 2019. \\nSeven countries in the Eastern Mediterranean Region have reported',\n",
       " '15. Roberton T, Carter ED, Chou VB, Stegmuller AR, Jackson BD, Tam Y, et al. Early estimates of the indirect effects of the COVID-19',\n",
       " '• Progression and impact of the COVID-19 pandemic  ..................................................................................................................... 1',\n",
       " 'Progression \\nand impact of \\nthe COVID-19 \\npandemic01',\n",
       " 'Classification of Diseases (10th revision) was key to enable countries \\nto identify the impact of COVID-19 to cause deaths within their top \\n10 leading causes of death. Mortality data for Lebanon, Oman, Qatar,']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What was effect of covid 19 in middle east?'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_similar_context = [item[0] for item in sorted_chunk_score_list[-5:]] # extract just the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['or recommended by WHO in preference to others of a similar nature that are not mentioned. Errors and \\nomissions excepted, the names of proprietary products are distinguished by initial capital letters.',\n",
       " 'third-party-owned component in the work rests solely with the user.\\nGeneral disclaimers.  The designations employed and the presentation of the material in this publication do not',\n",
       " 'requests for commercial use and queries on rights and licensing, see https:/ /www.who.int/copyright. \\nThird-party materials.  If you wish to reuse material from this work that is attributed to a third party, such as',\n",
       " 'suggestion that WHO endorses any specific organization, products or services. The use of the WHO logo is \\nnot permitted. If you adapt the work, then you must license your work under the same or equivalent Creative',\n",
       " 'Under the terms of this licence, you may copy, redistribute and adapt the work for non-commercial purposes, \\nprovided the work is appropriately cited, as indicated below. In any use of this work, there should be no']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_similar_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The COVID-19 pandemic had a significant impact in the Middle East region, leading to excess deaths in countries like Iraq and Tunisia when compared to 2019. The use of the Classification of Diseases (10th revision) enabled countries such as Lebanon, Oman, and Qatar to identify COVID-19 as a cause of death within their top leading causes. Seven countries in the Eastern Mediterranean Region have reported on the progression and impact of the pandemic.'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\n",
    "    \"context\": most_similar_context,\n",
    "    \"question\": query\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer was decent and with more data, better model and advanced RAG, we can perform even better.\n",
    "\n",
    "Now, let's see for least similar chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The context of the provided text does not contain specific information about the impact of COVID-19 on the Middle East. Therefore, I cannot provide a definitive answer based on the context alone. However, it is a widely known fact that the Middle East, particularly countries like Iran, Iraq, and Saudi Arabia, have been significantly affected by the COVID-19 pandemic in terms of high infection and death rates, economic disruption, and strained healthcare systems. Please refer to reliable news sources or health organizations for the most accurate and up-to-date information.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\n",
    "    \"context\": least_similar_context,\n",
    "    \"question\": query\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the context plays a very important role as model did not use it's knowledge to come up and answer the question. It is therefore very important to have context documents with high similarity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can filter contexts if their score is not good for large number of context documents by comparing score against a threshold value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set bigger number of similar docs to be found and filter if score on threshold\n",
    "\n",
    "similar_chunks_with_score = sorted_chunk_score_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here 0.6 is threshold meaning chunks with similarity score smaller than 0.6 must not be considered as they may give wrong/hallucinated answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_chunks_with_score_filtered = [s for s in similar_chunks_with_score if s[1]>0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now out of 20 only 6 are left as others had value smaller than threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_chunks_with_score_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can have condition where we return custom response if RAG cannot answer such question\n",
    "\n",
    "```py\n",
    "query = ...\n",
    "llm = ...\n",
    "similar_docs = getKClosestDocs(k=20) # returns k most similar docs\n",
    "threshold = 0.7\n",
    "similar_docs_filtered = [s for s in similar_chunks_with_score if s.score >threshold]\n",
    "\n",
    "if len(similar_docs_filtered)<3:\n",
    "    return \"Sorry, we cannot answer your question\"\n",
    "else:\n",
    "    return getLLMResponseWithContext(llm=llm, query=query, context=similar_docs_filtered)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this way, we can do better handling of cases where we avoid sending bad/hallucinated responses to user when context cannot be found for user query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
