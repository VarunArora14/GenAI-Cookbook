{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform RAG on a CSV dataset using ChromaDB as vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the important dependencies first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q dotenv pandas langchain langchain-community langchain-chroma langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 common ways we can handle CSV data for creating RAG apps - \n",
    "1. Convert CSV to dataframe providing explicit/automatically inference types from data and then split it to chunks\n",
    "2. Use CSVLoader to split CSV directly with each row as document taken\n",
    "\n",
    "Here we will use CSVLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similar documents using CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "csv_loader = CSVLoader(file_path=\"../../data/employee_data.csv\")\n",
    "csv_docs = csv_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_docs) # each row is again a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../../data/employee_data.csv', 'row': 0}, page_content='ï»¿EmpID: 3427\\nFirstName: Uriah\\nLastName: Bridges\\nStartDate: 20-Sep-19\\nExitDate: \\nTitle: Production Technician I\\nSupervisor: Peter Oneill\\nADEmail: uriah.bridges@bilearner.com\\nBusinessUnit: CCDR\\nEmployeeStatus: Active\\nEmployeeType: Contract\\nPayZone: Zone C\\nEmployeeClassificationType: Temporary\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Finance & Accounting\\nDOB: 07-10-1969\\nState: MA\\nJobFunctionDescription: Accounting\\nGenderCode: Female\\nLocationCode: 34904\\nRaceDesc: White\\nMaritalDesc: Widowed\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here each object is of type `Document` but it has different **metadata** where dataframe loader had remaining fields, this has source file name and row number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {'source': '../../data/employee_data.csv', 'row': 0},\n",
       " 'page_content': 'ï»¿EmpID: 3427\\nFirstName: Uriah\\nLastName: Bridges\\nStartDate: 20-Sep-19\\nExitDate: \\nTitle: Production Technician I\\nSupervisor: Peter Oneill\\nADEmail: uriah.bridges@bilearner.com\\nBusinessUnit: CCDR\\nEmployeeStatus: Active\\nEmployeeType: Contract\\nPayZone: Zone C\\nEmployeeClassificationType: Temporary\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Finance & Accounting\\nDOB: 07-10-1969\\nState: MA\\nJobFunctionDescription: Accounting\\nGenderCode: Female\\nLocationCode: 34904\\nRaceDesc: White\\nMaritalDesc: Widowed\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 4',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(csv_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to decide among these 2 techniques is to consider whether the entire row (all columns) are needed for similarity search or just one?\n",
    "\n",
    "If you need all then CSVLoader should be the choice, otherwise dataframeloader if you want only 1 column for similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initialise hugging face client for embeddings and LLM API calls\n",
    "\n",
    "- Create a file called `.env`\n",
    "- Login to hugging face hub and go to your profile => Settings => Access Tokens\n",
    "- Generate a new token and save it in the `.env` file as `HUGGINGFACEHUB_API_TOKEN=hf_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hugging_face_api_key = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to verify if key exists\n",
    "# print(hugging_face_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Hugging Face Inference Endpoint client to use Mistral 7b Instruct v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN ARORA\\AppData\\Local\\Temp\\ipykernel_16068\\1573641218.py:5: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  llm = HuggingFaceEndpoint(\n",
      "d:\\VS Code\\python\\GenAI-Cookbook\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\VARUN ARORA\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\" # last result of this\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create vector database chromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN ARORA\\AppData\\Local\\Temp\\ipykernel_16068\\1306845987.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "d:\\VS Code\\python\\GenAI-Cookbook\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# use the open-source embedding function to convert text to embeddings, can choose another function as per leaderboard - https://huggingface.co/spaces/mteb/leaderboard\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the documents using embedding function for `csv_docs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_chromadb_directory = \"chroma_rag_csvloader\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectorDB clients for docs while storing documents in vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvloader_db_client = Chroma.from_documents(documents=csv_docs, embedding=embedding_function, persist_directory=csv_chromadb_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the directories already exists, you have to call different method for client creation - \n",
    "\n",
    "`db = Chroma(persist_directory=\"my_directory\", embedding_function=embedding_function)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build simple RAG chain for csvloader vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VS Code\\python\\GenAI-Cookbook\\venv\\Lib\\site-packages\\langsmith\\client.py:312: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "from langchain import hub\n",
    "\n",
    "# set k as 20 to retrieve 20 most similar docs\n",
    "retriever = csvloader_db_client.as_retriever(search_kwargs={'k': 10})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\") # pull common RAG prompt here - https://smith.langchain.com/hub/rlm/rag-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is passed in to format each document retrieved from vector store to get the page content only as context to LLM\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "csvloader_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 1531, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 1958\\nFirstName: Lin\\nLastName: Chan\\nStartDate: 04-Jul-19\\nExitDate: \\nTitle: Production Technician I\\nSupervisor: Neil Aguilar\\nADEmail: lin.chan@bilearner.com\\nBusinessUnit: PYZ\\nEmployeeStatus: Active\\nEmployeeType: Contract\\nPayZone: Zone B\\nEmployeeClassificationType: Full-Time\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Sales & Marketing\\nDOB: 18-10-1990\\nState: MA\\nJobFunctionDescription: Assistant\\nGenderCode: Female\\nLocationCode: 2170\\nRaceDesc: Other\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 3'),\n",
       " Document(metadata={'row': 1911, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 2338\\nFirstName: Ivan\\nLastName: Hull\\nStartDate: 10-Oct-18\\nExitDate: 02-May-22\\nTitle: Production Manager\\nSupervisor: Robert Sullivan\\nADEmail: ivan.hull@bilearner.com\\nBusinessUnit: EW\\nEmployeeStatus: Active\\nEmployeeType: Part-Time\\nPayZone: Zone C\\nEmployeeClassificationType: Temporary\\nTerminationType: Involuntary\\nTerminationDescription: Body move possible play. Relate husband Mrs.\\nDepartmentType: Production\\nDivision: Project Management - Con\\nDOB: 06-08-1971\\nState: MA\\nJobFunctionDescription: Supervisor\\nGenderCode: Female\\nLocationCode: 6536\\nRaceDesc: Other\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 4'),\n",
       " Document(metadata={'row': 1930, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 2357\\nFirstName: Antoine\\nLastName: Murray\\nStartDate: 31-Dec-22\\nExitDate: 21-Jul-23\\nTitle: Production Manager\\nSupervisor: Erin Richard\\nADEmail: antoine.murray@bilearner.com\\nBusinessUnit: PL\\nEmployeeStatus: Active\\nEmployeeType: Contract\\nPayZone: Zone B\\nEmployeeClassificationType: Temporary\\nTerminationType: Involuntary\\nTerminationDescription: Where author federal Democrat in institution.\\nDepartmentType: Production\\nDivision: General - Con\\nDOB: 15-09-1943\\nState: MA\\nJobFunctionDescription: Foreman\\nGenderCode: Female\\nLocationCode: 48133\\nRaceDesc: Black\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 1'),\n",
       " Document(metadata={'row': 2026, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 2453\\nFirstName: Mila\\nLastName: Poole\\nStartDate: 13-May-23\\nExitDate: \\nTitle: Production Manager\\nSupervisor: Erin Abbott\\nADEmail: mila.poole@bilearner.com\\nBusinessUnit: CCDR\\nEmployeeStatus: Active\\nEmployeeType: Full-Time\\nPayZone: Zone C\\nEmployeeClassificationType: Full-Time\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Underground\\nDOB: 22-09-1988\\nState: MA\\nJobFunctionDescription: Laborer\\nGenderCode: Male\\nLocationCode: 70878\\nRaceDesc: Other\\nMaritalDesc: Widowed\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 1'),\n",
       " Document(metadata={'row': 2345, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 2772\\nFirstName: Alexandra\\nLastName: Bean\\nStartDate: 13-Mar-20\\nExitDate: \\nTitle: Production Technician I\\nSupervisor: Francis York\\nADEmail: alexandra.bean@bilearner.com\\nBusinessUnit: CCDR\\nEmployeeStatus: Active\\nEmployeeType: Full-Time\\nPayZone: Zone A\\nEmployeeClassificationType: Temporary\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Wireline Construction\\nDOB: 15-04-1973\\nState: MA\\nJobFunctionDescription: Laborer\\nGenderCode: Male\\nLocationCode: 74626\\nRaceDesc: Other\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 1'),\n",
       " Document(metadata={'row': 1887, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 2314\\nFirstName: Lia\\nLastName: Blair\\nStartDate: 19-Aug-19\\nExitDate: \\nTitle: Data Analyst\\nSupervisor: Vanessa Bell\\nADEmail: lia.blair@bilearner.com\\nBusinessUnit: PL\\nEmployeeStatus: Active\\nEmployeeType: Part-Time\\nPayZone: Zone C\\nEmployeeClassificationType: Part-Time\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: IT/IS\\nDivision: Field Operations\\nDOB: 18-10-1961\\nState: MA\\nJobFunctionDescription: Technician\\nGenderCode: Female\\nLocationCode: 48955\\nRaceDesc: Asian\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 1'),\n",
       " Document(metadata={'row': 1122, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 1549\\nFirstName: Sage\\nLastName: Potter\\nStartDate: 05-May-22\\nExitDate: \\nTitle: Production Technician I\\nSupervisor: Valerie Gregory\\nADEmail: sage.potter@bilearner.com\\nBusinessUnit: PL\\nEmployeeStatus: Active\\nEmployeeType: Part-Time\\nPayZone: Zone C\\nEmployeeClassificationType: Full-Time\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Executive\\nDOB: 16-01-1993\\nState: MA\\nJobFunctionDescription: Executive\\nGenderCode: Female\\nLocationCode: 25854\\nRaceDesc: Other\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 3'),\n",
       " Document(metadata={'row': 235, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 3662\\nFirstName: Hugh\\nLastName: Berry\\nStartDate: 13-Jun-23\\nExitDate: \\nTitle: Production Technician I\\nSupervisor: Linda Cummings\\nADEmail: hugh.berry@bilearner.com\\nBusinessUnit: NEL\\nEmployeeStatus: Active\\nEmployeeType: Full-Time\\nPayZone: Zone B\\nEmployeeClassificationType: Temporary\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Wireline Construction\\nDOB: 18-04-1973\\nState: MA\\nJobFunctionDescription: Laborer\\nGenderCode: Male\\nLocationCode: 90473\\nRaceDesc: Other\\nMaritalDesc: Married\\nPerformance Score: Exceeds\\nCurrent Employee Rating: 2'),\n",
       " Document(metadata={'row': 373, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 3800\\nFirstName: Amya\\nLastName: Grant\\nStartDate: 11-Jul-19\\nExitDate: \\nTitle: Production Technician I\\nSupervisor: Jamie Henderson\\nADEmail: amya.grant@bilearner.com\\nBusinessUnit: PYZ\\nEmployeeStatus: Active\\nEmployeeType: Contract\\nPayZone: Zone C\\nEmployeeClassificationType: Part-Time\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: General - Sga\\nDOB: 09-12-1950\\nState: MA\\nJobFunctionDescription: Administrator\\nGenderCode: Male\\nLocationCode: 31864\\nRaceDesc: Other\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 3'),\n",
       " Document(metadata={'row': 290, 'source': '../../data/employee_data.csv'}, page_content='ï»¿EmpID: 3717\\nFirstName: Keshawn\\nLastName: Le\\nStartDate: 18-May-23\\nExitDate: \\nTitle: Production Technician II\\nSupervisor: Samuel Turner\\nADEmail: keshawn.le@bilearner.com\\nBusinessUnit: EW\\nEmployeeStatus: Active\\nEmployeeType: Contract\\nPayZone: Zone B\\nEmployeeClassificationType: Full-Time\\nTerminationType: Unk\\nTerminationDescription: \\nDepartmentType: Production\\nDivision: Field Operations\\nDOB: 07-11-1992\\nState: MA\\nJobFunctionDescription: Specialist\\nGenderCode: Female\\nLocationCode: 21090\\nRaceDesc: Asian\\nMaritalDesc: Married\\nPerformance Score: Fully Meets\\nCurrent Employee Rating: 2')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 documents retrieved confirmed\n",
    "retriever.invoke(\"Which married employees have best performance?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = csvloader_rag_chain.invoke(\"Which married employees have best performance?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided context, Lin Chan and Ivan Hull are the married employees with the best performance scores of \"Fully Meets\" and current employee ratings of 3 and 4 respectively.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try and create same chain for `chromadb_rag_dfloader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Working Explanation\n",
    "\n",
    "The chain of operations can be visualized as follows:\n",
    "\n",
    "1. **Retrieve and Format Context**:\n",
    "    - The input query is sent to the `retriever`.\n",
    "    - The `retriever` fetches relevant documents.\n",
    "    - These documents are passed through `format_docs` to prepare them for the prompt.\n",
    "\n",
    "2. **Combine with Question**:\n",
    "    - Simultaneously, the question is passed through `RunnablePassthrough`.\n",
    "    - The `prompt` combines the formatted context and the question into a single prompt.\n",
    "\n",
    "3. **Generate Response**:\n",
    "    - This prompt is sent to the `llm`.\n",
    "    - The `llm` generates a response based on the prompt.\n",
    "\n",
    "4. **Parse Output**:\n",
    "    - The generated response is parsed by `StrOutputParser` to ensure it is in a clean string format.\n",
    "\n",
    "Here's the same explanation with the original code snippet for context:\n",
    "\n",
    "```python\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "### Breakdown\n",
    "\n",
    "1. `{\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}`:\n",
    "    - This dictionary contains two keys: `context` and `question`.\n",
    "    - `context` is formed by passing the input query through `retriever` and `format_docs` in sequence.\n",
    "    - `question` is directly passed through `RunnablePassthrough`.\n",
    "\n",
    "2. `| prompt`:\n",
    "    - The combined context and question are then passed to the `prompt`, which structures them into a single input for the LLM.\n",
    "\n",
    "3. `| llm`:\n",
    "    - The structured prompt is processed by the `llm`, which generates a response.\n",
    "\n",
    "4. `| StrOutputParser()`:\n",
    "    - The response from the LLM is parsed into a string format by `StrOutputParser`.\n",
    "\n",
    "This RAG chain ensures that the generated answer is relevant, well-formed, and based on the most pertinent context available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
